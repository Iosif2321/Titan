# Контекст проекта (сводка нашего обсуждения) — BTCUSDT Bybit Spot, TF=1m

Дата: 2025-12-21  
Статус: **Этап 1 (инференс + сбор данных + факт‑проверка) реализован**, обучение/оценка метрик — следующий этап.

---

## 1) Суть проекта (что он должен представлять)

Проект — это **система прогнозирования** (НЕ торговый бот) направления движения **BTCUSDT** на **Bybit Spot** на базовом таймфрейме **1 минута**.

**Ключевое:** проект делает **только предсказания**, собирает данные и артефакты для последующей оценки качества и обучения. Любая логика торговли, ордеров, позиций и т.п. — **вне текущего объёма**.

---

## 2) Источник данных и правила “правильной свечи”

### 2.1. Реал‑тайм данные
- Используем **публичные** данные Bybit через **WebSocket** (без API‑ключей).
- По умолчанию берём **только закрытые свечи** (confirmed=true), чтобы:
  - исключить “колеблющуюся” текущую минуту,
  - избежать рассинхрона и lookahead.

### 2.2. Heartbeat и устойчивость WS
- Heartbeat по спецификации Bybit: отправляем `{"op":"ping"}` каждые ~20 секунд (настраиваемо).
- При обрывах — реконнект с **экспоненциальным backoff** (до max 60 секунд) + корректная отмена фоновых задач.

### 2.3. История (для быстрого старта)
- Для скриптов, которым нужна история *сразу* (например, факт‑окно 5 направлений), используется **публичный REST** Bybit (без ключей) для подгрузки последних N свечей.
- История из локальных JSONL для инициализации **не используется как “источник истины”**, только как артефакт/лог (по твоему требованию).

---

## 3) Формулировка прогнозной задачи (Этап 1)

### 3.1. Выход модели
Модель выдаёт две вероятности:
- `p_up` — вероятность движения вверх
- `p_down` — вероятность движения вниз

### 3.2. FLAT (отсутствие направления)
FLAT — **не отдельная модель**, а правило “воздержаться”:
- если обе вероятности “низкие” и/или
- если разница вероятностей слишком мала (конфликт/неуверенность)

### 3.3. Таймфрейм
Базовый TF: **1m**.  
Горизонты прогнозирования и ансамбли — план на масштабирование, но не в первом этапе.

---

## 4) Стек и производительность

### 4.1. Фреймворк
- Выбран **JAX** как основной стек для инференса (и потенциально обучения).
- Цель: масштабирование на несколько моделей/таймфреймов и вычисления между свечами.

### 4.2. GPU / железо
- Целевая GPU: **NVIDIA GTX 1060 (SM 6.1)**.
- Рабочая среда: **WSL2** (Windows) + (опционально) **Docker** с `--gpus all`.
- JAX ставим как `jax[cuda12]`. CUDA 12 нужна из‑за совместимости с GTX 1060.

### 4.3. Ограничение времени
- Система должна уверенно успевать делать расчёты **за 1 минуту** даже при росте числа моделей (в будущем).

---

## 5) Архитектура проекта (модули и ответственность)

Цель архитектуры: **модульность и масштабирование**, чтобы добавлять:
- новые таймфреймы,
- новые модели,
- ансамбли,
- позже — “память паттернов”,
без переписывания ядра.

### 5.1. Основной пайплайн прогнозирования
- `bybit_ws.py`  
  WebSocket стрим свечей + парсер, heartbeat, reconnection, фильтр confirmed.
- `features.py`  
  Генерация признаков по окну: лог‑доходности + range/body последней свечи + z-score объёма.
- `model.py`  
  Базовая двухголовая модель на JAX (пока без обучения / с простой инициализацией).
- `predictor.py`  
  Держит окно, дедуп по `start_ts`, вызывает признаки и модель, применяет правило FLAT.
- `recording.py`  
  Запись артефактов в JSONL (UTF‑8): свечи и прогнозы.
- `main.py`  
  CLI‑раннер, логирование, флаги, диагностика JAX backend/devices.

### 5.2. Факт‑анализатор рынка (для проверки)
- `fact_movement.py`  
  Вычисляет “факт” направления по закрытиям:
  - направление для t = сравнение close(t) vs close(t-1)
  - поддерживает окно последних N направлений (обычно 5)
  - печатает цены close_prev/close_curr, delta, ret_bps
  - при обновлении печатает **только новые строки** (без повторов старых)

---

## 6) Артефакты (что пишем на диск)

Все артефакты пишутся в JSONL (1 запись = 1 строка JSON).

### 6.1. `candles.jsonl`
Поля (пример):
- `ts_start`, `ts_end`
- `o`, `h`, `l`, `c`
- `volume`
- `confirmed`

### 6.2. `predictions.jsonl`
Поля:
- `candle_ts` (ts_start свечи, на которой сформирован прогноз)
- `p_up`, `p_down`
- `direction` (UP/DOWN/FLAT)

### 6.3. `facts.jsonl` (опционально)
Поля:
- `prev_ts`, `candle_ts`
- `close_prev`, `close_curr`
- `delta`, `ret_bps`
- `direction`

---

## 7) Правила корректности (без самообмана)

- В режиме “только closed candles” — не используем текущую незакрытую минуту.
- Прогноз и факт должны быть **временно согласованы** при оценке:
  - предсказание, сделанное на закрытии минуты t, по смыслу можно оценивать на движении минуты t+1 (если именно это так определим на этапе оценки).
- Источник истины для факта — Bybit данные (WS/REST), а не локальные файлы.

---

## 8) Деплой и запуск

### 8.1. WSL2 (рекомендуемо для GTX 1060)
- Проверка GPU: `nvidia-smi`
- Установка зависимостей: `requirements-base.txt` + `jax[cuda12]` (GPU)
- Быстрая диагностика: `python -m src.main --dry-run` (должно показать `backend=gpu` и `CudaDevice(id=0)`)

### 8.2. Docker (опционально)
- Базовый образ: `python:3.10-slim`
- Установка: `pip install --upgrade "jax[cuda12]"` (в контейнере)
- Запуск: `docker run --gpus all ...`

---

## 9) Что уже реализовано (по факту обсуждения)

✅ Поднята среда WSL2 + JAX CUDA12, JAX видит GPU (`backend=gpu devices=[CudaDevice(id=0)]`).  
✅ WebSocket стабилен: heartbeat + exponential backoff reconnection.  
✅ Есть запись JSONL свечей/прогнозов.  
✅ Есть скрипт факт‑движения, который:
- выводит цены и направления,
- обновляется каждую минуту,
- не дублирует старые строки.

---

## 10) Что дальше (следующий этап развития)

### 10.1. Оценка качества модели (рекомендуемый следующий шаг)
Сделать `eval_predictions.py`, который:
- читает `predictions.jsonl` и `facts.jsonl`,
- корректно матчится по времени (например, pred(t) vs fact(t+1)),
- считает метрики:
  - accuracy/confusion matrix,
  - долю FLAT,
  - метрики по “решившимся” сигналам (без FLAT).

### 10.2. Обучение модели
- Подгрузка большой истории минуток через REST.
- Формирование датасета:
  - X(t) — признаки по окну до t
  - y(t+1) — направление/доходность следующей свечи (с порогом для FLAT при необходимости)
- Реализация обучения в JAX (или Flax/Optax), сохранение весов, загрузка в инференс.

### 10.3. Масштабирование (позже)
- Добавление таймфреймов (5m/15m/60m)
- Ансамбли моделей
- Система наград/штрафов (для контроля качества) и затем “память паттернов”

---

## 11) Важные принципы (которые мы закрепили)

- **Никакой торговли** в рамках проекта на текущем этапе (только прогнозы и валидация).
- **FLAT = abstain**, а не отдельная модель в MVP.
- **Модульность > монолит**, чтобы не переписывать ядро при росте.
- **WS для real-time**, **REST для warmup/истории**, оба без ключей.
- **WSL2/Docker** как основа для GPU JAX на GTX 1060.

---
